---
title: "Sampling distributions, simulation, and the linear model"
author: "Frank Edwards"
institute: School of Criminal Justice, Rutgers - Newark
date: "2/3/2021"
output: binb::metropolis
---

```{r message = FALSE, warning = FALSE, echo=FALSE}
set.seed(1)
library(tidyverse)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = F, size = "small")
theme_set(theme_minimal())
```

## Review HW1

- Challenges?

## Pulling from github

0. First, I'll demo how to add, commit, and push 

1. navigate to course folder

`cd intermediate_stats/`

2. fetch new changes to repository  

`git fetch`

3. merge them with the repository on your computer

`git merge`

# Sampling and sampling distributions

## The sampling model and population inference

Under the **sampling model** we use a subset of the data to **infer** characteristics about the population. 

I would like to know the average number of people living in a household in the United States. 

## Evaluating a sample


```{r size = "tiny", fig.height = 2}
draw_hh<-function(n){
  return(rpois(n, 1.53) + 1)
}

### sample 10 households
hh10<-draw_hh(10)
hh10
qplot(hh10)
```

## Infering population characteristics: mean

Let's assume this was a simple random sample (it was). We want to estimate $\mu$, the population average household size. We've observed $\bar{hh}_{10}$, more commonly written as $\bar{x}$.

```{r}
mean(hh10)
```

## Describing uncertainty in our inference

We could have observed many possible samples of 10 households

```{r echo = F, fig.height = 4}
hh10_sigma<-map(rep(10, 9), draw_hh)
plot_dat<-tibble(
  hh_size = unlist(hh10_sigma),
  sample_n = rep(1:9, each = 10)
) %>% 
  group_by(sample_n) %>% 
  mutate(mean_hh = mean(hh_size),
         se = sd(hh_size) / sqrt(n())) %>% 
  mutate(label = paste(sample_n,
                       ". ",
                       "mean = ",
                       mean_hh, 
                       sep = ""))

ggplot(plot_dat, 
       aes(x = hh_size)) + 
  geom_histogram() + 
  facet_wrap(~label, ncol = 3)
```

## The approximate sampling distribution of hh_10

Each sample of 10 could draw any one of these distributions of `hh_size`

```{r echo = F, fig.height = 5}
hh10_sigma<-map(rep(10,30), draw_hh)
plot_dat<-tibble(
  hh_size = unlist(hh10_sigma),
  sample_n = rep(1:30, each = 10)
) %>% 
  group_by(sample_n) %>% 
  mutate(mean_hh = mean(hh_size),
         se = sd(hh_size) / sqrt(n())) 

ggplot(plot_dat, 
       aes(x = hh_size)) + 
  geom_histogram() + 
  facet_wrap(~sample_n)
```

## The sampling distribution of a parameter

Just as our sample has a theoretical sampling distribution, our estimate of the sample mean $\bar{x}$ has a sampling distribution.

```{r echo = F, fig.height = 4}
ggplot(plot_dat %>% 
         select(sample_n, mean_hh) %>% 
         distinct(),
       aes(x = mean_hh)) + 
  geom_histogram() + 
  coord_cartesian(xlim = c(0, 6))+
  labs(title = "Empirical distribution of 30 observed sample means") 
```

## Constructing a parameter estimate from a sampling distribution estimate

We can use the *central limit theorem* ($\bar{x}\sim N(\mu, \sigma)$ as $n \rightarrow \infty$) to estimate a sampling distribution for a parameter from our observed data. 

We compute the sample mean ($\bar{x}$) and the *standard error* of the sample mean ($sd_x/\sqrt{n}$) to describe this distribution.

```{r}
hh10
mean(hh10)
sd(hh10) / sqrt(length(hh10))
```

## Visualizing the sampling distribution of sample means

We can describe our uncertainty in the estimate of $\mu$ with the estimated sampling distribution for $\bar{x}$, or the possible values of the sample mean we *could have* observed based on these data. \pause

\[\bar{x} \sim Normal (\hat{\bar{x}}, SE_{\hat{\bar{x}}})\] \pause

```{r, fig.height = 3, echo = F}
ggplot(plot_dat,
       aes(x = mean_hh)) + 
  #geom_histogram(aes(y = ..density..)) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(hh10), sd = sd(hh10)/sqrt(length(hh10)))) +
  xlim(0,4) + 
  labs(title = "Estimated sampling distribution of x bar",
       subtitle = paste("Mean = ", eval(mean(hh10)), "SE = ", 
                        eval(round(sd(hh10)/sqrt(length(hh10)),2))),
       y = "likelihood, conditional on the data",
       x = "possible values of x bar") 
```

\pause

We use these estimates to describe our uncertainty in the value of the *population parameter* $\mu$.

## Question

Using this sampling distribution, compute a 95 percent confidence interval for $\mu$. 

*Hint*: you can use `pnorm(0.025, 0, 1)` and `pnorm(0.975, 0, 1)` to obtain critical values for $z$.

```{r, fig.height = 3, echo = F}
ggplot(plot_dat,
       aes(x = mean_hh)) + 
  #geom_histogram(aes(y = ..density..)) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(hh10), sd = sd(hh10)/sqrt(length(hh10)))) +
  xlim(0,4) + 
  labs(title = "Estimated sampling distribution of x bar",
       subtitle = paste("Mean = ", eval(mean(hh10)), "SE = ", 
                        eval(round(sd(hh10)/sqrt(length(hh10)),2)),
                        "n = 10"),
       y = "likelihood, conditional on the data",
       x = "possible values of x bar") 
```


## The sampling distribution of the mean

```{r, echo = F}
### define sample sizes
sample_size<-c(5, 10, 30, 50, 100, 300, 500, 1000)
### draw samples
sample_hh<-map(sample_size, draw_hh)
### compute x_bar_hat and SE x_bar_hat for all samples sizes
params<-tibble(
  sample_size = sample_size,
  x_bar_hat = unlist(map(sample_hh, mean)),
  SE = unlist(map(sample_hh, sd))/sqrt(sample_size)
)
### compute normal densities from 1:4 for each sampling distribution
plot_dat<-data.frame(
  x_bar = rep(seq(from=1, to = 4, length.out = 100), length(sample_size)),
  n = rep(sample_size, each = 100),
  x_bar_hat = rep(params$x_bar_hat, each = 100),
  SE = rep(params$SE, each = 100)
) %>% 
  mutate(y = dnorm(x_bar, x_bar_hat, SE))

ggplot(plot_dat %>% 
         filter(n == sample_size[1]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 2.5, x = 1.5, 
            aes(label = paste("SE = ", round(SE,2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  ylim(0, 3)
```

## The sampling distribution of the mean

```{r, echo = F}
ggplot(plot_dat %>% 
         filter(n %in% sample_size[1:2]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 7.5, x = 2, 
            aes(label = paste("SE = ", round(SE, 2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  coord_cartesian(xlim = c(1,4), ylim = c(0,10))

```

## The sampling distribution of the mean

```{r, echo = F}
ggplot(plot_dat %>% 
         filter(n %in% sample_size[1:3]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 7.5, x = 2, 
            aes(label = paste("SE = ", round(SE, 2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  coord_cartesian(xlim = c(1,4), ylim = c(0,10))

```

## The sampling distribution of the mean

```{r, echo = F}
ggplot(plot_dat %>% 
         filter(n %in% sample_size[1:4]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 7.5, x = 2, 
            aes(label = paste("SE = ", round(SE, 2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  coord_cartesian(xlim = c(1,4), ylim = c(0,10))

```

## The sampling distribution of the mean

```{r, echo = F}
ggplot(plot_dat %>% 
         filter(n %in% sample_size[1:5]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 7.5, x = 2, 
            aes(label = paste("SE = ", round(SE, 2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  coord_cartesian(xlim = c(1,4), ylim = c(0,10))

```

## The sampling distribution of the mean

```{r, echo = F}
ggplot(plot_dat %>% 
         filter(n %in% sample_size[1:6]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 7.5, x = 2, 
            aes(label = paste("SE = ", round(SE, 2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  coord_cartesian(xlim = c(1,4), ylim = c(0,10))

```

## The sampling distribution of the mean

```{r, echo = F}
ggplot(plot_dat %>% 
         filter(n %in% sample_size[1:7]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 7.5, x = 2, 
            aes(label = paste("SE = ", round(SE, 2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  coord_cartesian(xlim = c(1,4), ylim = c(0,10))

```

## The sampling distribution of the mean

```{r, echo = F}
ggplot(plot_dat %>% 
         filter(n %in% sample_size[1:8]),
       aes(x = x_bar, y = y)) + 
  geom_line()+
  geom_vline(aes(xintercept = x_bar_hat), lty = 2, alpha = 0.5) + 
  geom_vline(aes(xintercept = 2.53), alpha = 0.5) + 
  labs(title = "Estimated sampling distribution of x bar",
       y = "likelihood, conditional on the data",
       x = "possible values of x bar")  + 
  geom_text(y = 7.5, x = 2, 
            aes(label = paste("SE = ", round(SE, 2)))) + 
  facet_wrap(~n, scales = "free", ncol = 4) + 
  coord_cartesian(xlim = c(1,4), ylim = c(0,10))

```

## Review

1. What is a parameter? \pause
1. What are the differences between $\bar{x}$, $\hat{\bar{x}}$, and $\mu$? \pause
1. What is the difference between a sample and a sampling distribution? \pause
1. Briefly explain the logic of a confidence interval through the logic of a sampling distribution

## Confidence intervals and sampling distributions

1. Let's draw 50 samples with 100 households sampled

```{r}
samp_hh<-data.frame(sample_n = rep(1:50, each = 100))
temp<-draw_hh(100)
for(i in 2:50){
  temp<-c(temp, 
          draw_hh(100))
}

samp_hh <- samp_hh %>% 
  mutate(hh_size = temp)
```

## Confidence intervals and sampling distributions

1. Let's draw 50 samples with 100 households sampled
2. Let's compute 95 percent confidence intervals for $\bar{x}$ for each sample

```{r}
samp_ci<-samp_hh %>% 
  group_by(sample_n) %>% 
  summarise(xbarhat = mean(hh_size),
            se = sd(hh_size)/sqrt(100)) %>% 
  mutate(ci_lwr = xbarhat - 1.96 * se,
         ci_upr = xbarhat + 1.96 * se)
```

## Confidence intervals and sampling distributions

1. Let's draw 50 samples with 100 households sampled
2. Let's compute 95 percent confidence intervals for $\bar{x}$ for each sample
3. Let's add a binary variable indicating whether the interval includes $\mu$ (2.53)

```{r}
samp_ci<- samp_ci %>% 
  mutate(sig_test.95 = ci_lwr<2.53 & ci_upr>2.53)
```

## Confidence intervals and sampling distributions

1. Let's draw 50 samples with 100 households sampled
2. Let's compute 95 percent confidence intervals for $\bar{x}$ for each sample
3. Let's add a binary variable indicating whether the interval includes $\mu$ (2.53)
4. Plot it!

```{r fig.height = 2, size = "tiny"}
ggplot(samp_ci,
       aes(ymin = ci_lwr, ymax = ci_upr, 
           y = xbarhat, x = sample_n,
           color = sig_test.95)) + 
  geom_pointrange() + 
  geom_hline(yintercept = 2.53, lty = 2) + 
  labs(x = "", y = "xbar", color = "Includes mu")
```

# Break

## Sampling distributions and regression parameters

We can apply the exact same logic to regression parameters. Let's use the `mpg` data to estimate the relationship between engine size (`displ`) and fuel efficiency (`hwy`).

```{r size = "tiny"}
glimpse(mpg)
```

## Estimate the model

We model fuel efficiency as a linear function of engine size with the model

\[y \sim N(\mu, \sigma^2)\]
\[\mu = \beta_0 + \beta_1 x\]

```{r}
m0<-lm(hwy ~ displ, data = mpg)
```

## What have we estimated?

```{r}
library(broom)
tidy(m0)
```

1. How does the `estimate` relate to the population mean? \pause
2. What does the standard error tell us? \pause
3. What is `statistic`? \pause
4. What about that p value?

## Let's interpret the model

```{r size = "tiny"}
tidy(m0)
```


1. What is the difference between $\hat{\beta}$ and $\beta$? \pause
1. What is $\beta_0$? \pause
2. What is $\beta_1$? \pause
3. Describe the relationship between engine size and fuel efficiency in terms of magnitude (M) and sign (S). \pause
4. How certain are we in these findings? How precise are you willing to be? \pause
5. What assumptions have we made?

## Homework

1. Catch up on the reading: Chapters 1-7
2. Catch up on DataCamp. Finish at least one of the assigned courses.
3. Complete the following book exercises: 3.1, 3.6, 4.1, 4.3, 4.7 (trick), 5.1, 5.3, 6.2 (hard)
