---
title: "Advanced models for count data"
author: "Frank Edwards"
output: binb::metropolis
---

```{r setup, echo = FALSE, message = FALSE}
rm(list=ls())
library(tidyverse)
library(broom)
library(rstan)
library(rstanarm)
library(broom)
### to optimize stan model fitting for your computer, enable parallel processing
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
select<-dplyr::select
set.seed(1)

options(xtable.comment = FALSE)
theme_set(theme_bw())
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(warning=FALSE, message=FALSE, tidy = TRUE, size = "small")
```

## Count data

- Counts are cumulative totals of the number of incidences of some event, generally across time or place \pause
- Counts are positive integers $\in [0,\infty]$  \pause
- We can model count variables using the Poisson distribution

## The Poisson distribution (lambda = 1)

```{r, echo = F, fig.height = 3}
pois_1<-rpois(10000, 1)
table(pois_1)
qplot(pois_1)
```

## The Poisson distribution (lambda = 3)

```{r, echo = F, fig.height = 3}
pois_1<-rpois(10000, 3)
table(pois_1)
qplot(pois_1)
```

## The Poisson distribution (lambda = 7)

```{r, echo = F, fig.height = 3}
pois_1<-rpois(10000, 7)
table(pois_1)
qplot(pois_1)
```

## The Poisson distribution (lambda = 30)

```{r, echo = F}
pois_1<-rpois(10000, 30)
qplot(pois_1)
```

## The Poisson distribution (lambda = 150)

```{r, echo = F}
pois_1<-rpois(10000, 150)
qplot(pois_1)
```

## Special properties of the Poisson

- The variance and mean of a Poisson variable with parameter $\lambda$ are both equal to $\lambda$

\pause

```{r}
### draw a sample of 10,000 from a Poisson with lambda = 2.3
pois_demo<-rpois(10000, lambda = 2.3)
table(pois_demo)
```

\pause

```{r}
mean(pois_demo)
var(pois_demo)
```

## How well does a Poisson distribution fit our soccer data?

- Is the mean / variance assumption of a Poisson reasonable for our NWSL data on goal scoring?

```{r}
### Load in NWLS data
load("./data/fieldplayer_overall_season_stats.rda")
nwsl_stats<-fieldplayer_overall_season_stats 
### Check if mean == variance
mean(nwsl_stats$gls)
var(nwsl_stats$gls)
```

## Comparing distributions

```{r}
### Draws from a Poisson with nrow() observations and lambda = mean(nwls$goals) 
sim1 <- rpois(nrow(nwsl_stats), lambda = mean(nwsl_stats$gls))
### simulation 
table(sim1)
### observed
table(nwsl_stats$gls)
```

## What's going on here?

- Problem 1: Player position is associated with goal scoring, right? Defenders don't score many (or any) goals. \pause

\pause

```{r}
nwsl_stats %>% 
  group_by(pos) %>% 
  summarize(gls_mn = mean(gls))
```

## So would simulating by position help yield a better fit?

```{r}
### compute mean, variance, and N for each position
positions<-nwsl_stats %>% 
  group_by(pos) %>% 
  summarize(obs_mn = mean(gls),
            obs_var = var(gls),
            n_obs = n())

positions
```

## So would simulating by position help yield a better fit?

```{r}
### now simulate 10000 player - season totals by position
positions <- positions %>% 
  group_by(pos) %>% 
  mutate(sim_mn = mean(rpois(n_obs, obs_mn)),
         sim_var = var(rpois(n_obs, obs_mn)))

positions
```

## What's going on here?

- Problem 1: Scoring is *clustered* by player position \pause

## Wait what's a cluster

A cluster is a subset of the population that has similar values to other members of the subset, and  systematically different values from other subsets of the population.

\pause

Clustering can produce differences in both the expected value and variance of variables across subsets.

## Sources of clustering

- A probability distribution assumes that all observations are drawn from the *same* population \pause
- But in practice, most data come from distinct sub-populations \pause

## Sources of clustering in the NWLS data?

What are some sub-populations in this data that may result in clustering?

```{r size = "tiny"}
glimpse(nwsl_stats)
```

## Overdispersion

Overdispersion is the presence of greater variability than we would expect from a given statistical model

\pause

For a Poisson model, we assume that 

$$var(x) = \bar{x} = \lambda$$

\pause

If $var(x) > \bar{x}$, then the data are *overdispresed* relative to predictions from the Poisson model.

## Clustering and overdispersion

When data come from distinct sub-populations, or clusters, they can have different underlying *data generating processes* (the real world process that produces our observations that we try to approximate using a statistical model). \pause

These differences in data generating processes often result in a) different expected values across sub-groups, and b) different levels of variability across sub-groups

## Poisson expectation

```{r echo = F}
positions<-nwsl_stats %>% 
  group_by(pos) %>% 
  summarize(obs_mn = mean(gls),
            obs_var = var(gls),
            n_obs = n())

nwsl_sim<-nwsl_stats %>% 
  left_join(positions) %>% 
  mutate(obs_n = 1:n()) %>% 
  group_by(obs_n) %>% 
  mutate(sim_gls = rpois(1, obs_mn))

ggplot(nwsl_sim,
       aes(x = sim_gls)) + 
  geom_histogram(fill = "blue", alpha = 0.5) + 
  facet_wrap(~pos, scales = "free") +
  labs(subtitle = "Blue = simulated from Poisson with lambda = position mean")
```

## Overdispersion

```{r echo = F}
ggplot(nwsl_sim,
       aes(x = sim_gls)) + 
  geom_histogram(fill = "blue", alpha = 0.5) + 
  geom_histogram(aes(x = gls), fill = "red", alpha = 0.5) +
  facet_wrap(~pos, scales = "free") +
  labs(subtitle = "Blue = simulated from Poisson, Red = observed")
```

## Overdispersion

```{r}
nwsl_sim %>% 
  group_by(pos) %>% 
  summarize(obs_var = var(gls),
            sim_var = var(sim_gls))
```

# Break

## Modeling overdispersion: adding a shape parameter

We could theoretically relax the $var(x) = \bar{x}$ assumption of the Poisson likelihood with a *quasi-Poisson* likelihood that has the following properties:

$$E(x) = \lambda$$
$$var(x) = \theta \lambda$$

\pause

We call $\theta$ an dispersion or shape parameter. Higher values of $\theta$ result in more variability, lower values of $\theta$ result in more concentration.

## The Negative Binomial model

The negative binomial model is very similar to the quasi-poisson. It includes a mean parameter $\mu$ and a shape parameter $\theta$.

We can define a negative binomial likelihood as

$$x \sim \textrm{Negative Binomial}(\mu, \theta)$$

\pause

With an expected value

$$\bar{x} = \mu$$

and variance

$$var(x) = \mu + \frac{\mu^2}{\theta}$$

## Let's see how these likelihoods differ

```{r size = "tiny"}
goals_poisson<-stan_glm(gls ~ pos,
                        family = poisson, data = nwsl_stats)

goals_negbin<-stan_glm(gls ~ pos,
                       family = neg_binomial_2(), data = nwsl_stats)
```

## Draw from the posterior predictive distributions

```{r size = "tiny"}
### simulate for each position
fake_data <- tibble(pos = unique(nwsl_stats$pos))
### from the poisson model
sim_pois<-posterior_predict(goals_poisson, newdata = fake_data)
colnames(sim_pois)<-fake_data$pos
### from the negative binomial mode
sim_negbin<-posterior_predict(goals_negbin, newdata = fake_data)
colnames(sim_negbin)<-fake_data$pos

### let's look at values for person_id 6 (row 3, a forward)
##### POISSON
mean(sim_pois[,which(fake_data$pos=="FW")]) 
var(sim_pois[,which(fake_data$pos=="FW")])
#### NEGATIVE BINOMIAL
mean(sim_negbin[,which(fake_data$pos=="FW")]) 
var(sim_negbin[,which(fake_data$pos=="FW")])
### WHOA!
```

## Let's visualize the difference in model predictions

```{r echo = F}
### Reshape for plotting
sim_pois<-as_tibble(sim_pois) %>% 
  pivot_longer(cols = 1:ncol(sim_pois)) %>% 
  mutate(model = "Poisson")

sim_negbin<-as_tibble(sim_negbin) %>% 
  pivot_longer(cols = 1:ncol(sim_negbin)) %>% 
  mutate(model = "Negative Binomial")

###  stick them together for plotting
plot_dat<-sim_pois %>% 
  rbind(sim_negbin)

ggplot(plot_dat,
       aes(x = value, 
           fill = model)) + 
  geom_histogram() + 
  labs(x = "Predicted goals") + 
  facet_wrap(~name, scales = "free")
```

## And compare the estimated variance to the observed

```{r echo = F}
tab_out<-sim_pois %>% 
  group_by(name) %>% 
  summarise(pois_var = var(value)) %>% 
  left_join(sim_negbin %>% 
              group_by(name) %>% 
  summarise(negbin_var = var(value))) %>% 
  rename(pos = name) %>% 
  left_join(positions %>% 
              select(-n_obs, -obs_mn)) 

plot_dat<-tab_out%>% 
  pivot_longer(cols = pois_var:obs_var,
               names_to = "type",
               values_to = "variance")

ggplot(plot_dat,
       aes(y = variance, x = pos, fill = type)) + 
  geom_col(position = position_dodge(), color = "black") + 
  labs(x = "Position",
       fill = "",
       y = "Variance")
```

## Offsets can improve model fit

Goals are a function of position, sure, but also a function of games played.

\pause

An *offset* term can be added to our model to convert our count into a rate. 

\pause

Here, we can add `mp` as a measure of time

## The model for the mean

Using matches played as our offset variable

$$\textrm{goals} \sim \textrm{NegBin}(\mu, \theta)$$

$$\log(\mu) = \beta \times \textrm{position} + \log(\textrm{mp})$$

## A generic form

$$\log(\mu) = \beta X + \log(\textrm{offset})$$
\pause

Because $log(x) - log(y) = log(x/y)$ This can be rewritten as

$$\log \left( \frac{\mu}{\textrm{offset}} \right) = \beta X$$
\pause

That's a rate! With the inverse of the link function ($e$ here), we can write this as 

$$\frac{\mu}{\textrm{offset}} = e^{\beta X}$$

## Let's fit the model again

```{r}
goals_negbin_offset<-stan_glm(gls ~ pos,
                       family = neg_binomial_2(), 
                       offset = log(mp),
                       data = nwsl_stats)
```

## Now we can compare model fits

```{r}
### Run the leave-one-out goodness of fit test
loo_m1<-loo(goals_negbin)
loo_m2<-loo(goals_negbin_offset)

loo_compare(loo_m1, loo_m2)
```

The offset dramatically improves our model fit. Let's see how this works.

## The regression parameters

Let's compute the estimated number of goals under each model for a forward

$$\log(\textrm{goals}) = \beta_0 + \beta_1 \times \textrm{position}$$

```{r}
posterior_interval(goals_negbin)
```

## The regression parameters: pffset model

Let's compute the estimated number of goals under each model for a forward

$$\log(\frac{\textrm{goals}}{\textrm{games}}) = \beta_0 + \beta_1 \times \textrm{position}$$

```{r}
posterior_interval(goals_negbin_offset)
```

## Homework 7 Due in two weeks (4/21)

\scriptsize 

Replicate (kinda) my paper on police violence, race, and place: `https://ajph.aphapublications.org/doi/abs/10.2105/AJPH.2018.304559`

1. Load in data on men killed by police by county (./hw/data/fe_division_rural.csv)
2. Compute and visualize death rates for each racial / ethnic group in the data (per 100,000 population)
3. Compute and visualize differences in death rates across Census divisions (`division`) and racial groups
4. Compute and visualize differences in death rates across county types (`ur.code`) and racial groups
5. Estimate a negative binomial model for counts of Black men killed by police using an appropriate offset
6. Estimate a negative binomial model for counts of white men killed by police using an appropriate offset
7. Compare the posterior intervals for expected deaths for Black and white men
8. Estimate new models using predictors for county type and census division and briefly describe your findings
9. Use leave-one-out cross validation to compare the models including county and division predictors to the intercept-only models (questions 5 and 6)

## Data structure for fe_division_rural
 
\scriptsize 
Data derived from Fatal Encounters and US Census

- fips: 5 digit county identifier
- state: two letter state abbreviation
- black.men: adult Black male population in county (age >= 18)
- white.men: adult white male population in county
- latino.men: adult Latino population in county
- tot.men: Total adult male population in county
- ur.code: US Dept of Agriculture rural - urban continuum classification for county
- division: US Census geographic division
- d.asian: Asian / PI men killed by police in county (age >= 18)
- d.black: Black men killed by police
- d.latino: Latino men killed by police
- d.other: men with other race/ethnicity identified killed by police
- d.white: white men killed by police
- d.na: men with missing race/ethnicity data killed by policy
- d.total: total men killed by police