---
title: "HW1"
subtitle: "Intermediate Statistics"
author: "YOU"
date: "SUBMISSION DATE"
output: html_document
---

```{r setup, echo = F, message = F}
library(tidyverse)
```


Read Gelman, Hill and Vehtari Chapters 1 through 4. Then, respond to the following questions.

## Part 1

1. Explain what the term *inference* means in your own words. Describe how statistical analysis generally relates to inference and scientific knowledge. Distinguish key differences between classical approaches to inference and Bayesian approaches to inference. (1-3 paragraphs)

```{r}

```



2. Briefly describe your past experience with statistics, math, and programming. What areas do you feel strong in? In what areas do you think you'll need extra support? (PS everyone can do this and it's ok to feel overwhelmed!)

Your response here

## Part 2

For the following, complete the listed problems from the Exercises at the end of each chapter.

3.1 *Weighted averages*

```{r}
### givens
# higher tax support
# age 18-29 (n=200): 50%
# age 30-44 (n = 250) : 60%
# age 45-64 (n=300): 40%
# age 65+ (n=250): 30%

data3.1<-data.frame(age = c(18, 30, 45, 65),
                    prop_support = c(0.5, 0.6, 0.4, 0.3),
                    n = c(200, 250, 300, 250))
# now compute full proportion who support
# start by computing n_support

data3.1<-data3.1 %>% 
  mutate(n_support = n * prop_support)

# now compute proportion who support

data3.1 %>% 
  summarize(prop_support = sum(n_support)/sum(n))
```

3.3 *Probability distributions* 

Hint: the code chunk below shows how to plot a Normal distribution with mu=0, sigma = 1 using ggplot. You may need to adjust plot_data as you modify mu and sigma. 

```{r}
# load packages
library(tidyverse)
# establish bounds for x
plot_data<-data.frame(x = c(-4, 4))
# plot
ggplot(plot_data,
       aes(x = x)) + 
  # stat_function evaluates the specified function over x (Normal PDF here)
  # args lets us modify the call to dnorm with arguments
  stat_function(fun = dnorm, 
                args = list(mean = 0, sd = 1))
```

3.6 *Linear transformations*

Hint: the code chunk below generates a line plot with specified intercept and slope using ggplot

```{r}
### givens
# range of test 0-50
# \bar{x} = 35, s_x = 10
# standardize it to \bar{x} = 100, s_x = 15
# first lets identify the slope 
# we can rescale the sd like this
b<-15 / 10

# now we can find a
# we know using y = a + bx that 100 = a + 1.5 * 35
# so a = 100 - 1.5 * 35
a<-100 - b * 35



```

so the transformation is y = `r a` + `r b` * x

```{r}
# range of transformation is g(0) and g(50) as bounds
# lower
a + b*0
# upper
a + b*50
```

plot it

```{r}
ggplot() + 
  geom_abline(slope = 1.5, intercept = 47.5) + 
  # lims() specifies limits of plotting window
  lims(x = c(-100, 100), y = c(-100, 100)) 
```

3.8 *Correlated random variables*

```{r}
# given
# cor(x, y) = 0.3
# x ~ N(69.1, 2.9)
# y ~ N(63.7, 2.7)
# compute mean and sd of (x+y)/2
# mean is easy
(69.1 + 63.7) / 2
# sd is trickier, use the sum of correlated random variables
# sqrt of squared SD for each + 2 times covariance (cor * sd * sd)
# make sure to apply the 1/2 'weight'
sqrt(0.5 * 2.9^2 + 0.5 * 2.7^2 + 0.5 * 2 * 0.3 * 2.7 * 2.9)
```

4.1 *Comparison of proportions*

```{r}
# givens
# rct n = 1000
# treatment (50%) $5 incentive, control $0
# 50% response for treatment, 40% for control
# compute ATE and SE
n<-1000
n_trt<-n * 0.5
n_ctrl<-n*0.5
x_trt<-n_trt * 0.5
x_ctrl<-n_ctrl * 0.4
# ATE = E[treatment - control]
# OR (x_trt - x_ctrl) / n
1/n * (x_trt - x_ctrl)
# SE = sqrt(se_trt + se_ctrl)
se_trt<-sqrt(0.5 * (1-0.5)/n)
se_ctrl<-sqrt(0.4 * (1-0.4)/n)
# se_ate
sqrt(se_trt + se_ctrl)
```

4.2 *Choosing sample size*

givens: 
simple random sample, binary outcome, SE < .05, solve for n
we know that variance is maximized at p = 0.5 for a binomial random variable
so we can solve assuming both are 0.5
se_men = sqrt(0.5 * 0.5 / n)
se_women = sqrt(0.5 * 0.5 / n)
se_diff = sqrt(se_men^2 + se_women^2)
0.05^2 = 2(0.5^2/n)
0.05^2/2 * n = 0.5^2
n = 0.5^2 / (0.05^2/2)
n = 200


4.3 *Comparison of proportions*

What is Pr(s_2 - s_1 > 0)?

```{r}
## shooter 1, 0.3, n = 20; y ~ binom(20, 0.3)
## shooter 2, 0.4, n = 20; x ~ binom(20, 0.4)
## simulate a solution
# 1000 trials for each shooter
n_trials<-1000

x_sim<-rbinom(n_trials, 20, 0.4)
y_sim<-rbinom(n_trials, 20, 0.3)
## compute how many had y>x
sum(y_sim>x_sim)
## as a proportion (we can treat as probability)
sum(y_sim>x_sim) / n_trials
## this is an approximate solution. You can try increasing
# n_trials if you want to see how it improves precision
```


## Part 3

There are two options for the course final project. 

1) Conduct a collaborative research project using data on police violence that the instructor will scaffold and advise. This project will be supported in lab sessions.

2) Conduct an independent research project on a topic of your own choosing. 

Tell me which option you are pursuing, then do the following:

*If pursuing option 1*, access and explore the data available in the course repository at `~/data/mpv_1_3_24.csv`. Read some prior research I've conducted using similar data available [here](https://www.pnas.org/doi/abs/10.1073/pnas.1821204116). Using group_by() and summarize() compute year-specific counts of people killed by police. Provide a line plot using ggplot() and geom_line() that visualizes the total number of people killed by police annually for 2012 - 2024. Briefly discuss your findings, and interpret in dialogue with prior research.

*If pursuing option 2*, complete the following exercises from the book: 1.10, 2.10, and 4.10. Provide appropriate context and discussion.
