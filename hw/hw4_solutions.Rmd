---
title: "Untitled"
author: "Frank Edwards"
date: "3/2/2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(broom)
library(rstan)
library(rstanarm)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

dat<-read_csv("./data/revenue_dat.csv")
```

## Homework

Repeat this process with a new outcome: `violent.yr`. This variable is a measure of the average number of violent index crimes known to police in a county per year. Build a model that helps us explain variation in violent crime across counties and/or over time. 

1. Describe your theory in plain english.

I think that places with higher levels of deep poverty (income less than 200 percent of the poverty line) are likely to have higher levels of violent crime, because structural inequalities are linked with community violence.

2. Describe a linear model that matches your theory (provide equations for the model).

\[y_i \sim N(\mu_i, \sigma^2)\]
\[\mu_i = \beta_0 + \beta_1x_{1i}\]

3. Fit that model using `lm()`

```{r}
### turn violent crime into a rate, crime per 1,000 people per year
### also transform pct_deep_pov to a percentage scale rather than proportion
dat<-dat %>% 
  mutate(violent.pc = violent.yr / pop_tot * 1e3,
         pop_pct_deep_pov = pop_pct_deep_pov * 100)

m0<-stan_glm(violent.pc ~ pop_pct_deep_pov,
       data = dat)

m0_f<-lm(scale(violent.pc) ~ scale(pop_pct_deep_pov),
       data = dat)

m0_post<-as.data.frame(m0)

```


4. Interpret the parameter estimates for that model. 

When no one is in deep poverty in a county, the model predicts `r coef(m0)[1]` violent crimes per 1,000 people per year. The model predicts that violent crimes will increase by `r coef(m0)[2]` for a one percent increase in the population in deep poverty. 


5. Visualize this model

```{r}
### extract posterior for b0, b1
m0_post<-as_tibble(m0)

### show median posterior for \mu = \beta_0 + \beta_1x

ggplot(dat,
       aes(y = violent.pc, x = pop_pct_deep_pov)) + 
  geom_point(alpha = 0.5) + 
  geom_abline(intercept = median(m0_post$`(Intercept)`), slope = median(m0_post$pop_pct_deep_pov)) + 
  labs(title = "With median posterior fit")

### show uncertainty for \mu with all the sampled values for b0, b1

ggplot(dat,
       aes(y = violent.pc, x = pop_pct_deep_pov)) + 
  geom_point(alpha = 0.5) + 
  geom_abline(intercept = m0_post$`(Intercept)`, slope = m0_post$pop_pct_deep_pov, color = "blue") + 
  labs(title = "With median posterior fit")
```

6. Add an appropriate interaction term. Explain your choice.

I'll add an interaction for racial segregation. More segregated places likely have higher violent crime as a function of exclusion and structural violence. Those levels are likely to be higher when poverty is high.

```{r}
m1<-stan_glm(violent.pc ~ pop_pct_deep_pov * dissim_bw,
       data = dat)

m1_post<-as.data.frame(m1)
```

7. Visualize this new model with an interaction

We'll set scenarios for low, median, and high segregation along the range of observed deep poverty percent. I create a sequence of poverty values from 0 to 30, then repeat this sequence for the 10th, 50th, and 90th percentile of Black / white segregation to simulate.

```{r}

fake_data_mid<-tibble(pop_pct_deep_pov = c(6.8 - 3.4, 6.8, 6.8+3.4),
                  dissim_bw = 50)

fake_data_low<-tibble(pop_pct_deep_pov = c(6.8 - 3.4, 6.8, 6.8+3.4),
                  dissim_bw = 35)

fake_data_high<-tibble(pop_pct_deep_pov = c(6.8 - 3.4, 6.8, 6.8+3.4),
                  dissim_bw = 65)

yhat<-posterior_linpred(m1, newdata=fake_data_mid)




yhat<-data.frame(yhat)

fake_data<-tibble(scenario = 1:90, ### making a key for the left_joins below
                  pop_pct_deep_pov = rep(seq(1, 30, by = 1),3),
                  dissim_bw = c(rep(quantile(dat$dissim_bw, 0.1, na.rm=T), 30),
                                rep(median(dat$dissim_bw, na.rm=T), 30),
                                rep(quantile(dat$dissim_bw, 0.9, na.rm=T), 30)))

### posterior_linpred shows uncertainty in the linear predictor \mu (\beta_0 + \beta_1)
### posterior_predict includes sampling uncertainty in the outcome (driven by \sigma)

post_preds_lin<-posterior_linpred(m1, newdata = fake_data) 
post_preds<-posterior_predict(m1, newdata = fake_data)

### now let's visualize uncertainty in both the linear predictor \mu and outcome y
### convert to tidy format and join to the original data
### first let's make the predictions tidy, then we can compute intervals

post_preds_lin<-as_tibble(post_preds_lin) %>% 
  pivot_longer(cols = everything(),
               names_to = "scenario",
               values_to = "yhat") %>% 
  mutate(scenario = as.numeric(scenario)) %>% 
  left_join(fake_data)

post_preds<-as_tibble(post_preds) %>% 
  pivot_longer(cols = everything(),
               names_to = "scenario",
               values_to = "ypred") %>% 
  mutate(scenario = as.numeric(scenario)) %>% 
  left_join(fake_data)

### now compute 90 percent uncertainty intervals using group_by() %>% summarize()

post_preds_lin<-post_preds_lin %>% 
  group_by(scenario, pop_pct_deep_pov, dissim_bw) %>% 
  summarize(yhat_lwr = quantile(yhat, 0.05),
            yhat_upr = quantile(yhat, 0.95),
            yhat_med = median(yhat))

post_preds<-post_preds %>% 
  group_by(scenario, pop_pct_deep_pov, dissim_bw) %>% 
  summarize(ypred_lwr = quantile(ypred, 0.05),
            ypred_upr = quantile(ypred, 0.95),
            ypred_med = median(ypred)) 
  

ggplot(dat,
       aes(x = pop_pct_deep_pov, y = violent.pc)) + 
  geom_point(alpha = 0.3) + 
  geom_ribbon(data = post_preds_lin,
              aes(x = pop_pct_deep_pov,
                  y = yhat_med,
                  ymin = yhat_lwr,
                  ymax = yhat_upr,
                  fill = factor(dissim_bw)),
              alpha = 0.5) +
  labs(title = "uncertainty in average violent crime rates, linear predictor mu = beta_0 + beta_1")

ggplot(dat,
       aes(x = pop_pct_deep_pov, y = violent.pc)) + 
  geom_point(alpha = 0.3) + 
  geom_ribbon(data = post_preds, 
              aes(x = pop_pct_deep_pov,
                  y = ypred_med,
                  ymin = ypred_lwr,
                  ymax = ypred_upr,
                  fill = factor(dissim_bw)),
              alpha = 0.5)   + 
  labs(title = "uncertainty in predictions of violent crime rates")
```


8. Interpret the model 

The model shows that we expect to see higher levels of violent crime when both segregation and poverty are high, compared to places where segregation and poverty are low. Note that we have much greater uncertainty in the outcome itself than we do in the expected value of the outcome.